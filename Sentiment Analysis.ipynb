{"cells":[{"cell_type":"code","execution_count":17,"metadata":{"id":"xC6-cH_7f8cg"},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"]}],"source":["dataset = pd.read_csv('../Datasets/IMDB_Dataset.csv')\n","print(dataset.head())"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                              review  sentiment\n","0  One of the other reviewers has mentioned that ...          1\n","1  A wonderful little production. <br /><br />The...          1\n","2  I thought this was a wonderful way to spend ti...          1\n","3  Basically there's a family where a little boy ...          0\n","4  Petter Mattei's \"Love in the Time of Money\" is...          1\n"]}],"source":["clean_dataset = dataset.replace('positive',1).replace('negative',0)\n","print(clean_dataset.head())"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["splitValue = 0.8\n","\n","train = clean_dataset.sample(frac=splitValue, ignore_index=True)\n","validation = clean_dataset.drop(train.index)\n","train_labels = np.array(train['sentiment'])\n","validation_labels = np.array(validation['sentiment'])"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='OOV')\n","tokenizer.fit_on_texts(clean_dataset['review'])\n","train_sequences = tokenizer.texts_to_sequences(train['review'])\n","validation_sequences = tokenizer.texts_to_sequences(validation['review'])"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["padded = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=120, truncating='post')\n","validation_padded = tf.keras.preprocessing.sequence.pad_sequences(validation_sequences, maxlen=120, truncating='post')"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(200000, 16, input_length=120),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(6, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid'),\n","])"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","1250/1250 [==============================] - 12s 9ms/step - loss: 0.4387 - accuracy: 0.7859 - val_loss: 0.2360 - val_accuracy: 0.9122\n","Epoch 2/10\n","1250/1250 [==============================] - 14s 11ms/step - loss: 0.1751 - accuracy: 0.9365 - val_loss: 0.1183 - val_accuracy: 0.9603\n","Epoch 3/10\n","1250/1250 [==============================] - 17s 13ms/step - loss: 0.0404 - accuracy: 0.9907 - val_loss: 0.1002 - val_accuracy: 0.9675\n","Epoch 4/10\n","1250/1250 [==============================] - 15s 12ms/step - loss: 0.0075 - accuracy: 0.9990 - val_loss: 0.1102 - val_accuracy: 0.9671\n","Epoch 5/10\n","1250/1250 [==============================] - 15s 12ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.1216 - val_accuracy: 0.9664\n","Epoch 6/10\n","1250/1250 [==============================] - 14s 12ms/step - loss: 4.2335e-04 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9667\n","Epoch 7/10\n","1250/1250 [==============================] - 16s 13ms/step - loss: 1.7314e-04 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9676\n","Epoch 8/10\n","1250/1250 [==============================] - 17s 14ms/step - loss: 7.8147e-05 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9676\n","Epoch 9/10\n","1250/1250 [==============================] - 22s 18ms/step - loss: 3.6720e-05 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9679\n","Epoch 10/10\n","1250/1250 [==============================] - 26s 21ms/step - loss: 1.7331e-05 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9674\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x2ce14f950>"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(padded, train_labels, epochs=10, validation_data=(validation_padded, validation_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def predict(sentence):\n","    new_sequence = tokenizer.texts_to_sequences([sentence])\n","    new_padded = tf.keras.preprocessing.sequence.pad_sequences(new_sequence, maxlen=120, truncating='post')\n","\n","    prediction = model.predict(new_padded)\n","\n","    sentiment_score = prediction[0][0]\n","    sentiment_label = \"positive\" if sentiment_score >= 0.5 else \"negative\"\n","\n","    print(f\"Sentence: {sentence}\")\n","    print(f\"Sentiment: {sentiment_label} (Score: {sentiment_score:.4f})\")\n","\n","predict(input())\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPZWNL/o0RbHnNyrLyBRwwP","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
